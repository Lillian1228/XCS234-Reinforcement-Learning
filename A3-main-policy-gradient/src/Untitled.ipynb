{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a93e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.25\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "rewards = [1,2,3]\n",
    "gamma = 0.5\n",
    "for t in range(len(rewards)):\n",
    "    print(gamma**t)\n",
    "    print(rewards[t]*gamma**t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6375402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.25, 2.75, 2.0, 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.5\n",
    "G_t = 0\n",
    "rewards = [1,2,3,4]\n",
    "returns = []\n",
    "for t in range(len(rewards)):\n",
    "    G_t += gamma**t*rewards[t]\n",
    "    returns.append(G_t)\n",
    "returns.reverse()\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f5c71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.25, 4.5, 5.0, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.reverse()\n",
    "returns = []\n",
    "cur = rewards[0]\n",
    "returns.append(cur)\n",
    "for i, r in enumerate(rewards[1:]):\n",
    "    cur = r + gamma * cur\n",
    "    returns.append(cur)\n",
    "\n",
    "returns.reverse()\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ed0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a06d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 18.0, 32.0, 58.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_returns = None\n",
    "returns = []\n",
    "for i in range(len(rewards)):\n",
    "    if previous_returns is None:\n",
    "        temp_returns = 0\n",
    "        for j in range(len(rewards)):\n",
    "            temp_returns += gamma ** i * rewards[j]\n",
    "    else:\n",
    "        temp_returns = (previous_returns - rewards[i - 1]) / gamma  # noqa\n",
    "    returns.append(temp_returns)\n",
    "    previous_returns = temp_returns\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b38587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(5, 7, dtype=torch.double)\n",
    "a.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "942864d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "config_file = open(\"config/{}.yml\".format(\"cartpole_baseline\"))\n",
    "config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config[\"env\"][\"seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcaed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== START GRADING\n",
      "----- START 1b-0-basic: test baseline for the existence of optimizer\n",
      "----- END 1b-0-basic [took 0:00:00.034336 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START 1c-0-basic: test policy for the existence of optimizer\n",
      "cpu\n",
      "----- END 1c-0-basic [took 0:00:00.010748 (max allowed 3 seconds), 1/1 points]\n",
      "\n",
      "----- START 1e-0-basic: test get_returns with basic trajectory\n",
      "cpu\n",
      "----- END 1e-0-basic [took 0:00:00.004647 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START 1e-1-basic: test get_returns for discounted trajectory\n",
      "cpu\n",
      "----- END 1e-1-basic [took 0:00:00.004244 (max allowed 1 seconds), 3/3 points]\n",
      "\n",
      "----- START 1f-0-basic: test sampled actions (cartpole)\n",
      "cpu\n",
      "----- END 1f-0-basic [took 0:00:00.068814 (max allowed 5 seconds), 3/3 points]\n",
      "\n",
      "----- START 1f-1-basic: test sampled actions (pendulum)\n",
      "cpu\n",
      "----- END 1f-1-basic [took 0:00:00.368283 (max allowed 7 seconds), 4/4 points]\n",
      "\n",
      "----- START 1f-2-basic: test sampled actions (cheetah)\n",
      "cpu\n",
      "----- END 1f-2-basic [took 0:00:00.021916 (max allowed 7 seconds), 4/4 points]\n",
      "\n",
      "----- START 1g-0-basic: test log probabilities (cartpole)\n",
      "cpu\n",
      "cpu\n",
      "----- END 1g-0-basic [took 0:00:00.015047 (max allowed 4 seconds), 2/2 points]\n",
      "\n",
      "----- START 1g-1-basic: test log probabilities (pendulum)\n",
      "cpu\n",
      "cpu\n",
      "----- END 1g-1-basic [took 0:00:00.019536 (max allowed 4 seconds), 2/2 points]\n",
      "\n",
      "----- START 1g-2-basic: test log probabilities (cheetah)\n",
      "cpu\n",
      "cpu\n",
      "----- END 1g-2-basic [took 0:00:00.020427 (max allowed 4 seconds), 2/2 points]\n",
      "\n",
      "Note that the hidden test cases do not check for correctness.\n",
      "They are provided for you to verify that the functions do not crash and run within the time limit.\n",
      "Points for these parts not assigned by the grader unless the solution is present (indicated by \"???\").\n",
      "========== END GRADING [23/23 points + 0/0 extra credit]\n"
     ]
    }
   ],
   "source": [
    "!python grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8db19f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Moviepy - Building video C:\\Users\\a647000\\Documents\\XCS234\\XCS234-A3-main\\src\\results\\CartPole-v1-1-no-baseline\\rl-video-step-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\a647000\\Documents\\XCS234\\XCS234-A3-main\\src\\results\\CartPole-v1-1-no-baseline\\rl-video-step-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a647000\\Anaconda3\\envs\\XCS234_A3\\lib\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at C:\\Users\\a647000\\Documents\\XCS234\\XCS234-A3-main\\src\\results\\CartPole-v1-1-no-baseline folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\a647000\\Anaconda3\\envs\\XCS234_A3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "\n",
      "t:   0%|          | 0/61 [00:00<?, ?it/s, now=None]\n",
      "t:   3%|3         | 2/61 [00:00<00:06,  9.74it/s, now=None]\n",
      "t:  72%|#######2  | 44/61 [00:00<00:00, 177.43it/s, now=None]\n",
      "                                                             \n",
      "Average reward: 22.13 +/- 1.00\n",
      "Average reward: 31.66 +/- 2.19\n",
      "Average reward: 61.88 +/- 4.61\n",
      "Average reward: 116.53 +/- 10.99\n",
      "Average reward: 130.33 +/- 7.13\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 172.91 +/- 17.81\n",
      "Average reward: 181.60 +/- 17.46\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 190.60 +/- 8.50\n",
      "Average reward: 181.00 +/- 7.14\n",
      "Average reward: 115.59 +/- 7.22\n",
      "Average reward: 94.76 +/- 1.72\n",
      "Average reward: 91.14 +/- 1.05\n",
      "Average reward: 89.95 +/- 0.91\n",
      "Average reward: 81.25 +/- 4.55\n",
      "Average reward: 78.08 +/- 4.65\n",
      "Average reward: 80.83 +/- 4.15\n",
      "Average reward: 90.62 +/- 2.56\n",
      "Average reward: 93.24 +/- 0.74\n",
      "Average reward: 91.86 +/- 0.77\n",
      "Average reward: 93.71 +/- 0.75\n",
      "Average reward: 94.62 +/- 1.09\n",
      "Average reward: 95.50 +/- 1.47\n",
      "Average reward: 103.42 +/- 4.94\n",
      "Average reward: 101.16 +/- 0.75\n",
      "Average reward: 102.74 +/- 1.28\n",
      "Average reward: 107.11 +/- 0.85\n",
      "Average reward: 111.35 +/- 0.94\n",
      "Average reward: 103.05 +/- 0.53\n",
      "Average reward: 96.95 +/- 2.85\n",
      "Average reward: 73.63 +/- 5.28\n",
      "Average reward: 85.87 +/- 4.21\n",
      "Average reward: 103.58 +/- 0.91\n",
      "Average reward: 111.94 +/- 1.13\n",
      "Average reward: 124.00 +/- 1.03\n",
      "Average reward: 141.43 +/- 2.43\n",
      "Average reward: 185.60 +/- 4.83\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 199.20 +/- 0.76\n",
      "Average reward: 199.40 +/- 0.57\n",
      "Average reward: 186.10 +/- 3.15\n",
      "Average reward: 190.40 +/- 3.64\n",
      "Average reward: 198.80 +/- 0.81\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 200.00 +/- 0.00\n",
      "Average reward: 198.70 +/- 1.23\n",
      "Average reward: 173.82 +/- 2.04\n",
      "Average reward: 165.75 +/- 2.23\n",
      "Average reward: 147.77 +/- 1.43\n",
      "Average reward: 143.77 +/- 1.12\n",
      "Average reward: 140.07 +/- 1.31\n",
      "Average reward: 132.47 +/- 1.10\n",
      "Average reward: 126.40 +/- 1.13\n",
      "Average reward: 131.13 +/- 1.30\n",
      "Average reward: 124.62 +/- 0.85\n",
      "Average reward: 118.25 +/- 1.04\n",
      "Average reward: 109.06 +/- 0.81\n",
      "Average reward: 90.59 +/- 4.46\n",
      "Average reward: 48.58 +/- 5.24\n",
      "Average reward: 51.03 +/- 5.59\n",
      "Average reward: 76.88 +/- 6.02\n",
      "Average reward: 86.77 +/- 5.12\n",
      "Average reward: 79.96 +/- 5.62\n",
      "Average reward: 95.55 +/- 0.63\n",
      "Average reward: 96.55 +/- 0.73\n",
      "- Training done.\n",
      "Loaded backend agg version v2.2.\n",
      "OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n"
     ]
    }
   ],
   "source": [
    "!python run.py --config_filename cartpole_no_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21e0f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a647000\\Anaconda3\\envs\\XCS234_A3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "Average reward: 8.05 +/- 0.12\n",
      "Average reward: 10.59 +/- 0.22\n",
      "Average reward: 18.82 +/- 0.55\n",
      "Average reward: 33.78 +/- 1.10\n",
      "Average reward: 43.01 +/- 1.40\n",
      "Average reward: 53.73 +/- 1.76\n",
      "Average reward: 36.34 +/- 1.07\n",
      "Average reward: 48.45 +/- 1.22\n",
      "Average reward: 57.64 +/- 1.77\n",
      "Average reward: 76.32 +/- 2.15\n",
      "Average reward: 81.69 +/- 1.88\n",
      "Average reward: 99.67 +/- 2.34\n",
      "Average reward: 119.51 +/- 4.17\n",
      "Average reward: 163.33 +/- 8.81\n",
      "Average reward: 269.05 +/- 24.60\n",
      "Average reward: 296.97 +/- 27.63\n",
      "Average reward: 241.54 +/- 11.19\n",
      "Average reward: 201.27 +/- 8.92\n",
      "Average reward: 165.72 +/- 4.55\n",
      "Average reward: 116.95 +/- 2.11\n",
      "Average reward: 119.87 +/- 2.53\n",
      "Average reward: 116.94 +/- 2.40\n",
      "Average reward: 117.89 +/- 1.94\n",
      "Average reward: 111.72 +/- 2.07\n",
      "Average reward: 119.23 +/- 2.92\n",
      "Average reward: 207.92 +/- 6.66\n",
      "Average reward: 858.45 +/- 70.31\n",
      "Average reward: 299.48 +/- 23.03\n",
      "Average reward: 260.51 +/- 22.65\n",
      "Average reward: 714.62 +/- 82.75\n",
      "Average reward: 768.25 +/- 87.74\n",
      "Average reward: 711.43 +/- 85.58\n",
      "Average reward: 569.44 +/- 81.59\n",
      "Average reward: 653.40 +/- 89.67\n",
      "Average reward: 692.64 +/- 97.64\n",
      "Average reward: 494.58 +/- 72.96\n",
      "Average reward: 355.93 +/- 47.33\n",
      "Average reward: 94.31 +/- 12.91\n",
      "Average reward: 43.69 +/- 0.32\n",
      "Average reward: 38.88 +/- 0.41\n",
      "Average reward: 37.27 +/- 0.46\n",
      "Average reward: 41.42 +/- 0.29\n",
      "Average reward: 45.59 +/- 0.24\n",
      "Average reward: 51.49 +/- 0.41\n",
      "Average reward: 70.60 +/- 1.27\n",
      "Average reward: 143.22 +/- 5.59\n",
      "Average reward: 832.55 +/- 68.42\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 925.00 +/- 71.15\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 930.50 +/- 65.93\n",
      "Average reward: 932.00 +/- 64.51\n",
      "Average reward: 901.50 +/- 93.34\n",
      "Average reward: 903.60 +/- 91.45\n",
      "Average reward: 969.70 +/- 28.75\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 979.20 +/- 19.73\n",
      "Average reward: 855.27 +/- 81.25\n",
      "Average reward: 927.40 +/- 65.17\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 925.20 +/- 54.62\n",
      "Average reward: 875.36 +/- 44.88\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 903.40 +/- 91.64\n",
      "Average reward: 759.83 +/- 120.08\n",
      "Average reward: 903.70 +/- 91.36\n",
      "Average reward: 759.25 +/- 120.38\n",
      "Average reward: 1000.00 +/- 0.00\n",
      "Average reward: 903.40 +/- 91.64\n",
      "Average reward: 824.82 +/- 112.05\n",
      "Average reward: 825.36 +/- 111.70\n",
      "Average reward: 400.13 +/- 93.28\n",
      "- Training done.\n",
      "Loaded backend agg version v2.2.\n",
      "OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n"
     ]
    }
   ],
   "source": [
    "!python run.py --config_filename pendulum_no_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d194bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum:\n",
    "  env_name: \"InvertedPendulum-v4\"\n",
    "  seed: [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81ba0f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n"
     ]
    }
   ],
   "source": [
    "!python run.py --plot_config_filename plot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82fd345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils.general import join, plot_combined\n",
    "import yaml\n",
    "yaml.add_constructor(\"!join\", join)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1229c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "No baseline\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_file = open(\"config/plot_test.yml\")\n",
    "config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "\n",
    "for env in config.keys():\n",
    "    gym_env_name = config[env][\"env_name\"]\n",
    "\n",
    "    all_results = {\"Baseline\": [], \"No baseline\": []}\n",
    "    for seed in config[env][\"seed\"]:\n",
    "        baseline_directory = \"./results/{}-{}-baseline/\".format(\n",
    "            gym_env_name, seed\n",
    "        )\n",
    "        no_baseline_directory = \"./results/{}-{}-no-baseline/\".format(\n",
    "            gym_env_name, seed\n",
    "        )\n",
    "        if not os.path.isdir(no_baseline_directory):\n",
    "            sys.exit(\n",
    "                \"{} was not found. Please ensure you have generated results for this environment, seed and baseline combination\".format(\n",
    "                    no_baseline_directory\n",
    "                )\n",
    "            )\n",
    "        if not os.path.isdir(baseline_directory):\n",
    "            sys.exit(\n",
    "                \"{} was not found. Please ensure you have generated results for this environment, seed and baseline combination\".format(\n",
    "                    baseline_directory\n",
    "                )\n",
    "            )\n",
    "        all_results[\"Baseline\"].append(\n",
    "            np.load(baseline_directory + \"scores.npy\")\n",
    "        )\n",
    "        all_results[\"No baseline\"].append(\n",
    "            np.load(no_baseline_directory + \"scores.npy\")\n",
    "        )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(gym_env_name)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    for name, results in all_results.items():\n",
    "        print(name)\n",
    "        plot_combined(name, results)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595bfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XCS234_A3",
   "language": "python",
   "name": "xcs234_a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
